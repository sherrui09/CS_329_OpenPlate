{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# prompt: install faiss\n",
        "\n",
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "id": "NFdlFZGwVfq4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afd551b3-021b-4924-ee62-d8aee159d531"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n",
            "Installing collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install fuzzywuzzy"
      ],
      "metadata": {
        "id": "t83V30AWNfhd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5c88988-7e50-4a51-ea6c-a0966d3eba47"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keybert"
      ],
      "metadata": {
        "id": "xYDYL3Ja6RwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get recipe dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNcW6pv8CnIk",
        "outputId": "150cdc1b-31b4-4ff7-c8a3-ec0572fbf9f5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "import numpy as np\n",
        "import faiss\n",
        "from keybert import KeyBERT\n",
        "import time"
      ],
      "metadata": {
        "id": "1Tv59U-oC8ZP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read Recipes and Filter by Calories_Per_Meal\n",
        "recipes = pd.read_csv('/content/drive/My Drive/CS329_Project/scraped-07-05-21.csv') # make path name your own.\n",
        "\n",
        "selected_recipes = []\n",
        "\n",
        "# search key words for dietary restriction, name + recipe to see if a recipe is... options for dietary restriction\n",
        "calories_per_meal = 800\n",
        "caloric_multiplier = 0.2\n",
        "caloric_deviation = calories_per_meal * caloric_multiplier\n",
        "min_calories_per_meal, max_calories_per_meal = calories_per_meal - caloric_deviation, calories_per_meal + caloric_deviation\n",
        "\n",
        "null_calories_count = recipes['calories'].isnull().sum()\n",
        "# print(null_calories_count)\n",
        "selected_recipes_df = recipes[(recipes['calories'] >= min_calories_per_meal) & (recipes['calories'] <= max_calories_per_meal)]\n",
        "selected_recipes_df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "tDwbYw3V8aVy"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index, recipe in selected_recipes_df.iterrows():\n",
        "  recipe_info = recipe['summary'] + ' ' + recipe['name']\n",
        "  if 'gluten' in recipe_info:\n",
        "    print(recipe_info)"
      ],
      "metadata": {
        "id": "qo-1SwgSCJA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For testing: To Select Random Recipes or Recipes in Order\n",
        "\n",
        "def select_recipes(recipes: DataFrame, n: int, random_selection: bool) -> DataFrame:\n",
        "  if n > len(recipes):\n",
        "    raise ValueError(\"Choose smaller n\")\n",
        "\n",
        "  if random_selection:\n",
        "    selected_recipes = recipes.sample(n=n, random_state=42)  # Use a fixed random state for reproducibility\n",
        "  else:\n",
        "    selected_recipes = recipes.head(n)\n",
        "  return selected_recipes\n",
        "\n",
        "recipe_count = 1000\n",
        "random_selection = False\n",
        "sample_recipes = select_recipes(selected_recipes_df, recipe_count, random_selection)\n",
        "# print(sample_recipes)"
      ],
      "metadata": {
        "id": "f6la9rt2eomI"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RECIPE_KEYWORDS = [] # pre-calculate the keywords to make KeyBERT methods faster. GLOBAL\n",
        "keybert_model = KeyBERT() # dont repeat instances\n",
        "\n",
        "# Extract keywords for each recipe in 'first100'\n",
        "for _, recipe in sample_recipes.iterrows():\n",
        "    summary           = recipe['summary']\n",
        "    title             = recipe['name']\n",
        "    title_and_summary = title + \" \" + summary\n",
        "    RECIPE_KEYWORDS.append(keybert_model.extract_keywords(title_and_summary))"
      ],
      "metadata": {
        "id": "6Gy7i-VSXe1s"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "V0L2Jc78CIKw"
      },
      "outputs": [],
      "source": [
        "# BERT AND COS\n",
        "\n",
        "# Need to implement NER/Topic modeling first, both on the user's preferences and the filtered recipes, ideally it would speed up the process\n",
        "# Sample BERT model that ranks recipes based on the user's preferences\n",
        "\n",
        "\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "class RecipeRankerCos:\n",
        "    def __init__(self):\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        self.model = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.model.eval()  # Set model to evaluation mode\n",
        "\n",
        "    def encode(self, text):\n",
        "        \"\"\"\n",
        "        Encodes a given text into embeddings using BERT.\n",
        "        \"\"\"\n",
        "        inputs = self.tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "        # Use the pooler output (representing te entire sentence) for simplicity\n",
        "        return outputs.pooler_output\n",
        "\n",
        "    def rank_recipes_by_taste_profile(self, recipes, taste_profile):\n",
        "        \"\"\"\n",
        "        Ranks recipes by their cosine similarity to the user's taste profile.\n",
        "        \"\"\"\n",
        "        # Convert the user's taste profile into an embedding\n",
        "        taste_profile_embedding = self.encode(taste_profile)\n",
        "\n",
        "        # Calculate similarity scores and rank recipes\n",
        "        ranked_recipes = []\n",
        "        for recipe in recipes.iterrows():\n",
        "            recipe_embedding = self.encode(recipe[1]['summary'])\n",
        "            similarity_score = cosine_similarity(taste_profile_embedding, recipe_embedding)\n",
        "            ranked_recipes.append((recipe, similarity_score.item()))\n",
        "\n",
        "        # Sort recipes based on similarity score\n",
        "        ranked_recipes.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "\n",
        "\n",
        "        # Return the sorted list of recipes\n",
        "        return [recipe for recipe, score in ranked_recipes]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT AND FAISS\n",
        "\n",
        "class RecipeRankerFAISS:\n",
        "    def __init__(self):\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        self.model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        self.model.eval()  # Set model to evaluation mode\n",
        "\n",
        "    def encode(self, text):\n",
        "        \"\"\"\n",
        "        Encodes a given text into embeddings using BERT.\n",
        "        \"\"\"\n",
        "        inputs = self.tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "        # Use the pooler output (representing the entire sentence) for simplicity\n",
        "        return outputs.pooler_output.numpy()\n",
        "\n",
        "    def rank_recipes_by_taste_profile(self, recipes, taste_profile):\n",
        "        \"\"\"\n",
        "        Ranks recipes by their cosine similarity to the user's taste profile.\n",
        "        \"\"\"\n",
        "        # Convert the user's taste profile into an embedding\n",
        "        taste_profile_embedding = self.encode(taste_profile)\n",
        "\n",
        "        # Encode all recipes into embeddings\n",
        "        recipe_embeddings = np.vstack([self.encode(summary) for summary in recipes['summary']])\n",
        "\n",
        "        # Setup FAISS index\n",
        "        d = taste_profile_embedding.shape[1]  # Dimension of the embeddings\n",
        "        index = faiss.IndexFlatL2(d)\n",
        "        index.add(recipe_embeddings)\n",
        "\n",
        "        # Perform a search to find the most similar recipes\n",
        "        k = 10  # Number of recipes to retrieve\n",
        "        _, indices = index.search(taste_profile_embedding, k)\n",
        "\n",
        "        # Retrieve the ranked recipes\n",
        "        ranked_recipes = recipes.iloc[indices[0]]\n",
        "\n",
        "        return ranked_recipes"
      ],
      "metadata": {
        "id": "eA9Y8CudOThz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keybert import KeyBERT\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "class RecipeRankerKeyBERT:\n",
        "    def __init__(self):\n",
        "        self.kw_model = KeyBERT()\n",
        "\n",
        "    def rank_recipes_by_taste_profile(self, recipes, taste_profile):\n",
        "        \"\"\"\n",
        "        Ranks recipes by their KeyBERT similarity to the user's taste profile.\n",
        "        \"\"\"\n",
        "        ranked_indices = []\n",
        "        # Extract keywords from the taste profile\n",
        "\n",
        "        taste_keywords = self.kw_model.extract_keywords(taste_profile)\n",
        "        key_scores = [score for _, score in taste_keywords]\n",
        "\n",
        "        for index in range(len(RECIPE_KEYWORDS)):\n",
        "          recipe_tuples = RECIPE_KEYWORDS[index]\n",
        "          recipe_scores = [score for _, score in recipe_tuples] # extract scores\n",
        "          if len(recipe_scores) >= 5:\n",
        "            similarity_score = cosine_similarity([key_scores], [recipe_scores])[0][0]\n",
        "            ranked_indices.append((index, similarity_score))\n",
        "\n",
        "        ranked_indices.sort(key=lambda x: x[1], reverse=True)\n",
        "        return [index for index, _ in ranked_indices]"
      ],
      "metadata": {
        "id": "eiGDCxGX3rH_"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import faiss\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "class RecipeRankerKeyBERT_FAISS:\n",
        "    def __init__(self):\n",
        "        self.kw_model = KeyBERT()\n",
        "\n",
        "    def rank_recipes_by_taste_profile(self, recipes, taste_profile):\n",
        "        \"\"\"\n",
        "        Ranks recipes by their KeyBERT similarity to the user's taste profile using FAISS.\n",
        "        \"\"\"\n",
        "\n",
        "        # Encode the taste profile\n",
        "        taste_keywords = self.kw_model.extract_keywords(taste_profile)\n",
        "        taste_vector = np.array([score for _, score in taste_keywords], dtype=np.float32)\n",
        "        # recipe_embeddings = np.vstack([np.array([score for _, score in self.kw_model.extract_keywords(summary)], dtype=np.float32) for summary in recipes['summary']])\n",
        "\n",
        "        recipe_embeddings = []\n",
        "\n",
        "        for index in range(len(RECIPE_KEYWORDS)):\n",
        "          recipe_tuples = RECIPE_KEYWORDS[index]\n",
        "          recipe_scores = [score for _, score in recipe_tuples] # extract scores\n",
        "          if len(recipe_scores) >= 5:\n",
        "            recipe_embeddings.append(recipe_scores)\n",
        "\n",
        "        recipe_embeddings = np.array(recipe_embeddings, dtype=np.float32)\n",
        "\n",
        "        # Setup FAISS index\n",
        "        d = recipe_embeddings.shape[1]  # Dimension of the embeddings\n",
        "        index = faiss.IndexFlatL2(d)\n",
        "        index.add(recipe_embeddings)\n",
        "\n",
        "        # Perform a search to find the most similar recipes\n",
        "        k = 10  # Number of recipes to retrieve\n",
        "        _, indices = index.search(np.expand_dims(taste_vector, axis=0), k)\n",
        "\n",
        "        # Retrieve the ranked recipes\n",
        "        ranked_indices = indices[0]\n",
        "\n",
        "        # Return the sorted list of recipes\n",
        "        return ranked_indices\n"
      ],
      "metadata": {
        "id": "9T0kpnobGyjV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fuzzywuzzy import fuzz\n",
        "\n",
        "class RecipeRankerKeyBERTfuzzy:\n",
        "    def __init__(self):\n",
        "        self.kw_model = KeyBERT()\n",
        "\n",
        "    def rank_recipes_by_taste_profile(self, recipes, taste_profile) -> list:\n",
        "        \"\"\"\n",
        "        Ranks recipes by their KeyBERT similarity to the user's taste profile.\n",
        "        \"\"\"\n",
        "\n",
        "        similarity_scores = []\n",
        "\n",
        "        taste_keywords = self.kw_model.extract_keywords(taste_profile)\n",
        "        key_words  = [word for word, _ in taste_keywords]\n",
        "\n",
        "        start = time.time()\n",
        "\n",
        "        for index in range(len(RECIPE_KEYWORDS)):\n",
        "          recipe_tuples = RECIPE_KEYWORDS[index]\n",
        "          recipe_words = [word for word, _ in recipe_tuples] # extract words\n",
        "          denom = len(key_words)\n",
        "\n",
        "          if denom != 0: # avoid div by 0\n",
        "            score = 0\n",
        "            for key_word in key_words:\n",
        "              score += fuzz.partial_ratio(key_word, recipe_words) / denom\n",
        "            similarity_scores.append((index, score))\n",
        "\n",
        "        end = time.time()\n",
        "        print(f'Running Time: {end - start}')\n",
        "\n",
        "        similarity_scores.sort(key=lambda x: x[1], reverse=True) # sort by highest mean\n",
        "        # print(similarity_scores[:10])\n",
        "\n",
        "        top_indices = [index for index, _ in similarity_scores]\n",
        "\n",
        "        return top_indices\n"
      ],
      "metadata": {
        "id": "0UVv5lG6OJFP"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def top10(ranked_recipes):\n",
        "  count = 0\n",
        "  for index, recipe in ranked_recipes:\n",
        "        print(recipe[0])\n",
        "        # print(recipe[4])\n",
        "        count +=1\n",
        "        if count == 10:\n",
        "          break\n",
        "\n",
        "def top10_indices(ranked_indices):\n",
        "  count = 0\n",
        "  for index in ranked_indices:\n",
        "    print(sample_recipes['name'][index])\n",
        "    # print(sample_recipes['summary'][index])\n",
        "    count += 1\n",
        "    if count >= 10: break"
      ],
      "metadata": {
        "id": "q3O1VCUdMTez"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "taste_profile = \"I want a dish that is Asian and has beef, vegetables, and rice\"\n",
        "\n",
        "ranker_KeyBERT_fuzzy = RecipeRankerKeyBERTfuzzy()\n",
        "RR_KeyBERT_fuzzy_indices = ranker_KeyBERT_fuzzy.rank_recipes_by_taste_profile(sample_recipes, taste_profile)"
      ],
      "metadata": {
        "id": "BX8aUdvExEKA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da47b686-90e6-4433-8e6a-c8b8b14da9b9"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Time: 0.9597389698028564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "taste_keywords = keybert_model.extract_keywords(taste_profile)\n",
        "key_words  = [word for word, _ in taste_keywords]\n",
        "\n",
        "print(key_words)\n",
        "print()\n",
        "print('========= KEYBERT FUZZY =============')\n",
        "print()\n",
        "top10_indices(RR_KeyBERT_fuzzy_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osoDMd0RCEg4",
        "outputId": "b7266a51-2ba3-4c5a-eeff-05cdb3728bb9"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['rice', 'dish', 'asian', 'vegetables', 'beef']\n",
            "\n",
            "========= KEYBERT FUZZY =============\n",
            "\n",
            "Malaysian Beef Rendang\n",
            "Italian Rice Balls\n",
            "Baked Rice (Ross Fil-Forn)\n",
            "Easy After Work Chicken Francaise\n",
            "Corned Beef and Cabbage I\n",
            "Authentic Seafood Paella\n",
            "Easy Smoked Sausage Skillet\n",
            "Best Bobotie\n",
            "Pasta Verde\n",
            "Chef John's Lasagna\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FUZZY TESTING for Best Method of fuzz string matching\n",
        "\n",
        "recipe_words1 = ['rice', 'dish', 'asian', 'beef', 'vegetables']\n",
        "recipe_words2 = ['oatmeal', 'cookies', 'raisins', 'moist', 'soft']\n",
        "recipe_words3 = ['recipe', 'chicken', 'ingredient', 'baked', 'cooked']\n",
        "recipe_words4 = ['cake', 'cupcakes', 'white', 'simplest', 'tasting']\n",
        "recipe_words5 = ['banana', 'bread', 'recipe', 'joy', 'seconds']\n",
        "recipe_words6 = ['tortellini', 'pesto', 'salads', 'salad', 'pasta']\n",
        "recipe_words7 = ['rice', 'restaurant', 'peas', 'vegetables', 'carrots']\n",
        "\n",
        "user_words    = ['rice', 'dish', 'asian', 'vegetables', 'beef']\n",
        "\n",
        "denom = 25\n",
        "total_score1, total_score2 = 0, 0\n",
        "for word in user_words:\n",
        "  for word2 in user_words:\n",
        "    total_score1 += fuzz.partial_ratio(word, word2) / 5\n",
        "for word in user_words:\n",
        "  for word2 in recipe_words1:\n",
        "    total_score2 += fuzz.partial_ratio(word, word2) / 5\n",
        "\n",
        "print(f'Total Score 1: {total_score1}')\n",
        "print(f'Total Score 2: {total_score2}')\n",
        "print()\n",
        "\n",
        "total_score1, total_score2 = 0, 0\n",
        "for word in user_words:\n",
        "  total_score1 += fuzz.partial_ratio(word, user_words)\n",
        "for word in user_words:\n",
        "  total_score2 += fuzz.partial_ratio(word, recipe_words1)\n",
        "\n",
        "print(f'Total Score 1: {total_score1 / 5}')\n",
        "print(f'Total Score 2: {total_score2 / 5}')\n",
        "print()\n",
        "# print(f'Ratio: {total_score / total_score2}')\n",
        "\n",
        "total_score1, total_score2 = 0, 0\n",
        "\n",
        "total_score1 = fuzz.partial_ratio(user_words, user_words)\n",
        "total_score2 = fuzz.partial_ratio(user_words, recipe_words1)\n",
        "\n",
        "print(f'Total Score 1: {total_score1}')\n",
        "print(f'Total Score 2: {total_score2}')\n",
        "\n",
        "# partial ratio:\n",
        "# \"rice\"\n",
        "# \"riceeeesnenw\"\n",
        "# Ratio: 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XFBmJdvksCk",
        "outputId": "1b9d0348-de34-4b3b-bf3c-46022beb95d8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Score 1: 199.2\n",
            "Total Score 2: 199.2\n",
            "\n",
            "Total Score 1: 100.0\n",
            "Total Score 2: 100.0\n",
            "\n",
            "Total Score 1: 100\n",
            "Total Score 2: 83\n"
          ]
        }
      ]
    }
  ]
}